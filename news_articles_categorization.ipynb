{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "news-articles-categorization.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOPSG7LR8XQ6IL63CX99HLd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/timthedev07/news-articles-classification/blob/dev/news_articles_categorization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import libraries"
      ],
      "metadata": {
        "id": "Z2uRBYIiWlWc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4EsrxrpzV0qO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import string\n",
        "import re\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D, Dropout\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import nltk\n",
        "import numpy as np\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stopWords = set(stopwords.words(\"english\"))\n",
        "stopWords.remove(\"not\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load data."
      ],
      "metadata": {
        "id": "6GTOwuFWW2iq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf ./sample_data\n",
        "!rm -rf ./data\n",
        "!mkdir data\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "!cp \"/content/gdrive/My Drive/datasets/news-articles-categorization/data.json.zip\" data\n",
        "%cd data\n",
        "!unzip -ojq data.json.zip\n",
        "!mv News_Category_Dataset_v2.json data.json\n",
        "!rm -rf data.json.zip\n",
        "%cd ..\n",
        "\n",
        "data = pd.read_json(\"data/data.json\", lines = True)"
      ],
      "metadata": {
        "id": "IWRZu2y2W4v5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = data[\"headline\"]\n",
        "y = pd.get_dummies(data[\"category\"])\n",
        "\n",
        "trainX, testX, trainY, testY = train_test_split(x, y, test_size = 0.2, random_state = 42, shuffle = True)\n",
        "\n",
        "LABELS = np.sort(data[\"category\"].unique())"
      ],
      "metadata": {
        "id": "JayhIkSshKG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Input cleaning."
      ],
      "metadata": {
        "id": "ZT0xGQCpkHni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def customStandardization(text: tf.Tensor):\n",
        "    # to lower case\n",
        "    text = tf.strings.lower(text)\n",
        "    # expand contraction\n",
        "    pairs = [\n",
        "        (\"won't\", \"will not\"),\n",
        "        (\"can't\", \"can not\"),\n",
        "        (\"n't\", \" not\"),\n",
        "        (\"'re\", \" are\"),\n",
        "        (\"'s\", \" is\"),\n",
        "        (\"'d\", \" would\"),\n",
        "        (\"'ll\", \" will\"),\n",
        "        (\"'t\", \" not\"),\n",
        "        (\"'ve\", \" have\"),\n",
        "        (\"'m\", \" am\"),\n",
        "    ]\n",
        "    for contracted, replacement in pairs:\n",
        "        text = tf.strings.regex_replace(text, contracted, replacement)\n",
        "    \n",
        "    # clean special symbols\n",
        "    text = tf.strings.regex_replace(text, r\"\\d+(?:\\.\\d*)?(?:[eE][+-]?\\d+)?\", \" \")\n",
        "    text = tf.strings.regex_replace(text, r'@([A-Za-z0-9_]+)', \" \")\n",
        "    text = tf.strings.regex_replace(text, r\"[^A-Za-z0-9]+\", \" \")\n",
        "\n",
        "    # remove stopwords\n",
        "    for i in stopWords:\n",
        "        text = tf.strings.regex_replace(text, f\"[^A-Za-z0-9_]+{i}[^A-Za-z0-9_]+\", \" \")\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "B6IBwuKIkI-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model."
      ],
      "metadata": {
        "id": "45PIAL6Kk6bb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    \n",
        "])"
      ],
      "metadata": {
        "id": "bJhfD3bDshmU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}